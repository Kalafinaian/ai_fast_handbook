{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import onnxruntime as ort\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 1\n",
    "N_BATCH = 128\n",
    "N_BATCH_NUM = 250\n",
    "S_DATA_PATH = r\"mnist_train.csv\"\n",
    "S_TORCH_MODEL_FULL_PATH = r\"cnn_model.pth\"\n",
    "S_TORCH_MODEL_PARAMS_PATH = r\"cnn_model_state.pth\"\n",
    "S_TORCH_MODEL_SCRIPT_PATH = r\"cnn_model.torch_script.pt\"\n",
    "S_ONNX_MODEL_PATH = r\"cnn_model_batch%d.onnx\" % N_BATCH\n",
    "S_DEVICE, N_DEVICE_ID, S_DEVICE_FULL = \"cuda\", 0, \"cuda:0\"\n",
    "# S_DEVICE, N_DEVICE_ID, S_DEVICE_FULL = \"cpu\", 0, \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(42000, 785)\n",
      "(32000, 1, 28, 28)\n",
      "(32000,)\n",
      "(10000, 1, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(S_DATA_PATH, header=None)\n",
    "print(df.shape)\n",
    "np_mat = np.array(df)\n",
    "print(np_mat.shape)\n",
    "\n",
    "X = np_mat[:, 1:]\n",
    "Y = np_mat[:, 0]\n",
    "X = X.astype(np.float32) / 255\n",
    "X_train = X[:N_BATCH * N_BATCH_NUM]\n",
    "X_test = X[N_BATCH * N_BATCH_NUM:]\n",
    "Y_train = Y[:N_BATCH * N_BATCH_NUM]\n",
    "Y_test = Y[N_BATCH * N_BATCH_NUM:]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "\n",
    "class MnistDataSet(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.l_data, self.l_label = [], []\n",
    "        for i in range(X.shape[0]):\n",
    "            self.l_data.append(X[i, :, :, :])\n",
    "            self.l_label.append(Y[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.l_data[index], self.l_label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l_data)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(MnistDataSet(X_train, Y_train), batch_size=N_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(MnistDataSet(X_test, Y_test), batch_size=N_BATCH, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=2704, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(nn.Conv2d(1, 16, 3, 1),\n",
    "                                           nn.MaxPool2d(2), nn.Flatten(1),\n",
    "                                           nn.Linear(2704, 128), nn.ReLU(),\n",
    "                                           nn.Linear(128, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = Net().to(S_DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model train\n",
      "train  tensor(116.0373, device='cuda:0', grad_fn=<AddBackward0>) 0.87025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"model train\")\n",
    "for i in range(N_EPOCH):\n",
    "    net.train()\n",
    "    t_loss = 0.\n",
    "    np_pred, np_y = None, None\n",
    "    for j, (t_x_b, t_y_b) in enumerate(train_loader):\n",
    "        t_y_b = t_y_b.long().to(S_DEVICE)\n",
    "        t_x_b = t_x_b.float().to(S_DEVICE)\n",
    "\n",
    "        t_logits_b = net(t_x_b)\n",
    "        t_loss_b = loss_fun(t_logits_b, t_y_b)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t_loss_b.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        t_loss += t_loss_b\n",
    "        np_pred_b = torch.argmax(t_logits_b, -1).detach().cpu().numpy()\n",
    "        np_pred = np_pred_b if np_pred is None else np.concatenate(\n",
    "            (np_pred, np_pred_b), 0)\n",
    "        np_y = t_y_b.cpu().numpy() if np_y is None else np.concatenate(\n",
    "            (np_y, t_y_b.cpu().numpy()), 0)\n",
    "\n",
    "    f_acc = accuracy_score(np_y, np_pred)\n",
    "    print(\"train \", t_loss, f_acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(18.5382, device='cuda:0') 0.9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(N_EPOCH):\n",
    "        net.eval()\n",
    "        t_loss = 0.\n",
    "        np_pred, np_y = None, None\n",
    "        for j, (t_x_b, t_y_b) in enumerate(test_loader):\n",
    "            t_y_b = t_y_b.long().to(S_DEVICE)\n",
    "            t_x_b = t_x_b.float().to(S_DEVICE)\n",
    "\n",
    "            t_logits_b = net(t_x_b)\n",
    "            t_loss_b = loss_fun(t_logits_b, t_y_b)\n",
    "\n",
    "            t_loss += t_loss_b\n",
    "\n",
    "            np_pred_b = torch.argmax(t_logits_b, -1).detach().cpu().numpy()\n",
    "            np_pred = np_pred_b if np_pred is None else np.concatenate(\n",
    "                (np_pred, np_pred_b), 0)\n",
    "            np_y = t_y_b.cpu().numpy() if np_y is None else np.concatenate(\n",
    "                (np_y, t_y_b.cpu().numpy()), 0)\n",
    "\n",
    "        f_acc = accuracy_score(np_y, np_pred)\n",
    "        print(\"test \", t_loss, f_acc)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, S_TORCH_MODEL_FULL_PATH)\n",
    "torch.save(net.state_dict(), S_TORCH_MODEL_PARAMS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load and Loaded Model Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load torch model and pred test data\n",
      "load model ok\n",
      "load torch model  tensor(18.5382, device='cuda:0') 0.9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"load torch model and pred test data\")\n",
    "net_load = torch.load(S_TORCH_MODEL_FULL_PATH,\n",
    "                      map_location=lambda storage, loc: storage)\n",
    "net_load = net_load.to(S_DEVICE)\n",
    "print(\"load model ok\")\n",
    "with torch.no_grad():\n",
    "    for i in range(N_EPOCH):\n",
    "        net_load.eval()\n",
    "        t_loss = 0.\n",
    "        np_pred, np_y = None, None\n",
    "        for j, (t_x_b, t_y_b) in enumerate(test_loader):\n",
    "            t_y_b = t_y_b.long().to(S_DEVICE)\n",
    "            t_x_b = t_x_b.float().to(S_DEVICE)\n",
    "\n",
    "            t_logits_b = net_load(t_x_b)\n",
    "            t_loss_b = loss_fun(t_logits_b, t_y_b)\n",
    "\n",
    "            t_loss += t_loss_b\n",
    "            np_pred_b = torch.argmax(t_logits_b, -1).detach().cpu().numpy()\n",
    "            np_pred = np_pred_b if np_pred is None else np.concatenate(\n",
    "                (np_pred, np_pred_b), 0)\n",
    "            np_y = t_y_b.cpu().numpy() if np_y is None else np.concatenate(\n",
    "                (np_y, t_y_b.cpu().numpy()), 0)\n",
    "\n",
    "        f_acc = accuracy_score(np_y, np_pred)\n",
    "        print(\"load torch model \", t_loss, f_acc)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Torch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  original_name=Net\n",
      "  (encoder): Sequential(\n",
      "    original_name=Sequential\n",
      "    (0): Conv2d(original_name=Conv2d)\n",
      "    (1): MaxPool2d(original_name=MaxPool2d)\n",
      "    (2): Flatten(original_name=Flatten)\n",
      "    (3): Linear(original_name=Linear)\n",
      "    (4): ReLU(original_name=ReLU)\n",
      "    (5): Linear(original_name=Linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch_script_trace = torch.jit.trace(net_load, t_x_b)\n",
    "print(torch_script_trace)\n",
    "torch_script_trace.save(S_TORCH_MODEL_SCRIPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Torch Script and Use Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=Net\n",
      "  (encoder): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (1): RecursiveScriptModule(original_name=MaxPool2d)\n",
      "    (2): RecursiveScriptModule(original_name=Flatten)\n",
      "    (3): RecursiveScriptModule(original_name=Linear)\n",
      "    (4): RecursiveScriptModule(original_name=ReLU)\n",
      "    (5): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  encoder = self.encoder\n",
      "  return (encoder).forward(x, )\n",
      "\n",
      "load scirpt model ok\n",
      "load scirpt torch model  tensor(18.5382, device='cuda:0') 0.9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch_script_load = torch.jit.load(S_TORCH_MODEL_SCRIPT_PATH)\n",
    "torch_script_load = torch_script_load.to(S_DEVICE)\n",
    "print(torch_script_load)\n",
    "print(torch_script_load.code)\n",
    "print(\"load scirpt model ok\")\n",
    "with torch.no_grad():\n",
    "    for i in range(N_EPOCH):\n",
    "        torch_script_load.eval()\n",
    "        t_loss = 0.\n",
    "        np_pred, np_y = None, None\n",
    "        for j, (t_x_b, t_y_b) in enumerate(test_loader):\n",
    "            t_y_b = t_y_b.long().to(S_DEVICE)\n",
    "            t_x_b = t_x_b.float().to(S_DEVICE)\n",
    "\n",
    "            t_logits_b = torch_script_load(t_x_b)\n",
    "            t_loss_b = loss_fun(t_logits_b, t_y_b)\n",
    "\n",
    "            t_loss += t_loss_b\n",
    "            np_pred_b = torch.argmax(t_logits_b, -1).detach().cpu().numpy()\n",
    "            np_pred = np_pred_b if np_pred is None else np.concatenate(\n",
    "                (np_pred, np_pred_b), 0)\n",
    "            np_y = t_y_b.cpu().numpy() if np_y is None else np.concatenate(\n",
    "                (np_y, t_y_b.cpu().numpy()), 0)\n",
    "\n",
    "        f_acc = accuracy_score(np_y, np_pred)\n",
    "        print(\"load scirpt torch model \", t_loss, f_acc)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%data : Float(*, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n",
      "      %encoder.0.weight : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.0.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.3.weight : Float(128, 2704, strides=[2704, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.3.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.5.weight : Float(10, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.5.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %7 : Float(*, 16, 26, 26, strides=[10816, 676, 26, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%data, %encoder.0.weight, %encoder.0.bias) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:444:0\n",
      "  %8 : Float(*, 16, 13, 13, strides=[2704, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%7) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:797:0\n",
      "  %9 : Float(*, 2704, strides=[2704, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%8) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:45:0\n",
      "  %input : Float(*, 128, strides=[128, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%9, %encoder.3.weight, %encoder.3.bias) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103:0\n",
      "  %11 : Float(*, 128, strides=[128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1442:0\n",
      "  %output : Float(*, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%11, %encoder.5.weight, %encoder.5.bias) # D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_in = torch.randn(N_BATCH, 1, 28, 28)\n",
    "torch.onnx.export(\n",
    "    net_load.cpu(),\n",
    "    dummy_in,\n",
    "    S_ONNX_MODEL_PATH,\n",
    "    verbose=True,\n",
    "    input_names=[\"data\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        'data': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "graph torch-jit-export (\n",
      "  %data[FLOAT, batch_sizex1x28x28]\n",
      ") initializers (\n",
      "  %encoder.0.weight[FLOAT, 16x1x3x3]\n",
      "  %encoder.0.bias[FLOAT, 16]\n",
      "  %encoder.3.weight[FLOAT, 128x2704]\n",
      "  %encoder.3.bias[FLOAT, 128]\n",
      "  %encoder.5.weight[FLOAT, 10x128]\n",
      "  %encoder.5.bias[FLOAT, 10]\n",
      ") {\n",
      "  %onnx::MaxPool_7 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [1, 1]](%data, %encoder.0.weight, %encoder.0.bias)\n",
      "  %onnx::Flatten_8 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%onnx::MaxPool_7)\n",
      "  %onnx::Gemm_9 = Flatten[axis = 1](%onnx::Flatten_8)\n",
      "  %input = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_9, %encoder.3.weight, %encoder.3.bias)\n",
      "  %onnx::Gemm_11 = Relu(%input)\n",
      "  %output = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_11, %encoder.5.weight, %encoder.5.bias)\n",
      "  return %output\n",
      "}\n",
      "input name  ['data']\n",
      "output name  ['output']\n",
      "val device  cuda\n",
      "val shape  [256, 1, 28, 28]\n",
      "val data type  tensor(float)\n",
      "is_tensor  True\n",
      "array_equal  True\n",
      "providers  CUDAExecutionProvider\n",
      "sess env  ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "<class 'list'>\n",
      "[[ -4.452876     5.936099     1.1340206  ...  -3.1742709    1.9301994\n",
      "   -4.37393   ]\n",
      " [ 11.914015   -13.1839       0.9041673  ...  -3.1198869    0.0822632\n",
      "   -2.5758023 ]\n",
      " [ -6.822728     7.317427     0.13283029 ...  -1.0278757    0.17321166\n",
      "   -3.2531943 ]\n",
      " ...\n",
      " [  0.9538739   -6.575384    -4.850646   ...   1.5700095   -1.497857\n",
      "   -0.68276715]\n",
      " [ -7.9123154   -3.5114594   -0.92229486 ...   5.1379223   -2.0123398\n",
      "    1.6533947 ]\n",
      " [ -4.9074783    5.651112     0.6526345  ...  -0.61784583  -0.45435312\n",
      "   -3.2060852 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nFor example ['CUDAExecutionProvider', 'CPUExecutionProvider']\\n    means execute a node using CUDAExecutionProvider if capable, otherwise execute using CPUExecutionProvider.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = onnx.load(S_ONNX_MODEL_PATH)\n",
    "print(onnx.checker.check_model(model))  # Check that the model is well formed\n",
    "print(onnx.helper.printable_graph(model.graph))  # Print a human readable representation of the graph\n",
    "ls_input_name, ls_output_name = [input.name for input in model.graph.input], [output.name for output in model.graph.output]\n",
    "print(\"input name \", ls_input_name)\n",
    "print(\"output name \", ls_output_name)\n",
    "s_input_name = ls_input_name[0]\n",
    "\n",
    "x_input = X_train[:N_BATCH*2, :, :, :].astype(np.float32)\n",
    "ort_val = ort.OrtValue.ortvalue_from_numpy(x_input, S_DEVICE, N_DEVICE_ID)\n",
    "print(\"val device \", ort_val.device_name())\n",
    "print(\"val shape \", ort_val.shape())\n",
    "print(\"val data type \", ort_val.data_type())\n",
    "print(\"is_tensor \", ort_val.is_tensor())\n",
    "print(\"array_equal \", np.array_equal(ort_val.numpy(), x_input))\n",
    "providers = 'CUDAExecutionProvider' if S_DEVICE == \"cuda\" else 'CPUExecutionProvider'\n",
    "print(\"providers \", providers)\n",
    "ort_session = ort.InferenceSession(S_ONNX_MODEL_PATH,\n",
    "                                   providers=[providers])  # gpu运行\n",
    "ort_session.set_providers([providers])\n",
    "outputs = ort_session.run(None, {s_input_name: ort_val})\n",
    "print(\"sess env \", ort_session.get_providers())\n",
    "print(type(outputs))\n",
    "print(outputs[0])\n",
    "'''\n",
    "For example ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "    means execute a node using CUDAExecutionProvider if capable, otherwise execute using CPUExecutionProvider.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
