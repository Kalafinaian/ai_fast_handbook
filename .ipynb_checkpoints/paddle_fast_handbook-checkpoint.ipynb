{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf6367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\urllib3\\util\\selectors.py:14: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import namedtuple, Mapping\n",
      "D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\urllib3\\_collections.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnx\n",
    "import paddle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import onnxruntime as ort\n",
    "import paddle.nn.functional as F\n",
    "from paddle.metric import Accuracy\n",
    "from paddle.static import InputSpec\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d5140",
   "metadata": {},
   "source": [
    "# Param Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f338c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDAPlace(0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCH = 2\n",
    "N_BATCH = 64\n",
    "N_BATCH_NUM = 250\n",
    "S_DATA_PATH = r\"mnist_train.csv\"\n",
    "S_PADDLE_MODEL_PATH = r\"cnn_model\"\n",
    "S_ONNX_MODEL_PATH = r\"cnn_model_batch%d.onnx\" % N_BATCH\n",
    "S_DEVICE, N_DEVICE_ID, S_DEVICE_FULL = \"gpu\", 0, \"gpu:0\"\n",
    "# S_DEVICE, N_DEVICE_ID, S_DEVICE_FULL = \"cpu\", 0, \"cpu\"\n",
    "paddle.set_device(S_DEVICE_FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54406e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb944a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(42000, 785)\n",
      "(16000, 1, 28, 28)\n",
      "(16000,)\n",
      "(26000, 1, 28, 28)\n",
      "(26000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(S_DATA_PATH, header=None)\n",
    "print(df.shape)\n",
    "np_mat = np.array(df)\n",
    "print(np_mat.shape)\n",
    "\n",
    "X = np_mat[:, 1:]\n",
    "Y = np_mat[:, 0]\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "X_train = X[:N_BATCH * N_BATCH_NUM]\n",
    "X_test = X[N_BATCH * N_BATCH_NUM:]\n",
    "Y_train = Y[:N_BATCH * N_BATCH_NUM]\n",
    "Y_test = Y[N_BATCH * N_BATCH_NUM:]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "class MnistDataSet(paddle.io.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.l_data, self.l_label = [], []\n",
    "        for i in range(X.shape[0]):\n",
    "            self.l_data.append(X[i, :, :, :])\n",
    "            self.l_label.append(Y[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.l_data[index], self.l_label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l_data)\n",
    "\n",
    "train_loader = paddle.io.DataLoader(MnistDataSet(X_train, Y_train),  batch_size=N_BATCH, shuffle=True)\n",
    "test_loader = paddle.io.DataLoader(MnistDataSet(X_test, Y_test), batch_size=N_BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce4bee",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f48648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = paddle.nn.Sequential(paddle.nn.Conv2D(1, 16, 3, 1),\n",
    "                                            paddle.nn.MaxPool2D(2),\n",
    "                                            paddle.nn.Flatten(1),\n",
    "                                            paddle.nn.Linear(2704, 128),\n",
    "                                            paddle.nn.ReLU(),\n",
    "                                            paddle.nn.Linear(128, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7e152",
   "metadata": {},
   "source": [
    "# Model Train and Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc20e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model train\n",
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/2\n",
      "step  30/250 [==>...........................] - loss: 0.3036 - acc: 0.7531 - ETA: 1s - 6ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 250/250 [==============================] - loss: 0.3151 - acc: 0.9073 - 4ms/step          \n",
      "save checkpoint at D:\\Document\\_Code_Py\\ai_fast_handbook\\cnn_model_iter\\0\n",
      "Eval begin...\n",
      "step 407/407 [==============================] - loss: 0.0230 - acc: 0.9330 - 2ms/step          - loss: 0.1698 - acc: 0.9315 - ETA: 0s - 2ms/ - loss: 0.3643 - acc: 0.9326 - ETA: 0s - 2m\n",
      "Eval samples: 26000\n",
      "Epoch 2/2\n",
      "step 250/250 [==============================] - loss: 0.0744 - acc: 0.9642 - 3ms/step          \n",
      "save checkpoint at D:\\Document\\_Code_Py\\ai_fast_handbook\\cnn_model_iter\\1\n",
      "Eval begin...\n",
      "step 407/407 [==============================] - loss: 0.0614 - acc: 0.9575 - 2ms/step          \n",
      "Eval samples: 26000\n",
      "save checkpoint at D:\\Document\\_Code_Py\\ai_fast_handbook\\cnn_model_iter\\final\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"model train\")\n",
    "model = paddle.Model(Net(), InputSpec([None, 1, 28, 28], 'float32', 'x'), InputSpec([None, 10], 'float32', 'x'))\n",
    "model.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), paddle.nn.CrossEntropyLoss(), Accuracy())\n",
    "model.fit(train_loader,\n",
    "          test_loader,\n",
    "          epochs=N_EPOCH,\n",
    "          batch_size=N_BATCH,\n",
    "          save_dir=S_PADDLE_MODEL_PATH + \"_iter\",\n",
    "          verbose=1)\n",
    "model.save(S_PADDLE_MODEL_PATH + \"_final_model\")\n",
    "print()\n",
    "# model.save(S_PADDLE_MODEL_PATH) # Model save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a132f10",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e216d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model pred\n",
      "Eval begin...\n",
      "step 407/407 [==============================] - loss: 0.0614 - acc: 0.9575 - 2ms/step          - loss: 0.2162 - acc: 0.9559 - ETA\n",
      "Eval samples: 26000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"model pred\")\n",
    "model.evaluate(test_loader, batch_size=N_BATCH, verbose=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa30975",
   "metadata": {},
   "source": [
    "# Model Load and Loaded Model Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe7a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model and pred test data\n",
      "Eval begin...\n",
      "step 407/407 [==============================] - loss: 0.0614 - acc: 0.9575 - 2ms/step          - loss: 0.1656 - acc: 0.9561 - ETA:\n",
      "Eval samples: 26000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"load model and pred test data\")\n",
    "model_load = paddle.Model(Net(), InputSpec([None, 1, 28, 28], 'float32', 'x'), InputSpec([None, 10], 'float32', 'x'))\n",
    "# model_load.load(S_PADDLE_MODEL_PATH + \"_iter/final\")\n",
    "model_load.load(S_PADDLE_MODEL_PATH + \"_final_model\")\n",
    "model_load.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), paddle.nn.loss.CrossEntropyLoss(), Accuracy())\n",
    "model_load.evaluate(test_loader, batch_size=N_BATCH, verbose=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933d6f9",
   "metadata": {},
   "source": [
    "# Export Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76b56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 08:08:21 [INFO]\tONNX model saved in cnn_model_batch64.onnx.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev_Utils\\Anaconda3\\lib\\site-packages\\onnx\\helper.py:343: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  is_iterable = isinstance(value, collections.Iterable)\n"
     ]
    }
   ],
   "source": [
    "x_spec = InputSpec([None, 1, 28, 28], 'float32', 'x')\n",
    "paddle.onnx.export(Net(), S_ONNX_MODEL_PATH, input_spec=[x_spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd46f3a",
   "metadata": {},
   "source": [
    "# Onnx Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa365aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "graph paddle-onnx (\n",
      "  %x[FLOAT, -1x1x28x28]\n",
      ") {\n",
      "  %conv2d_2.w_0 = Constant[value = <Tensor>]()\n",
      "  %conv2d_2.b_0 = Constant[value = <Tensor>]()\n",
      "  %linear_4.w_0 = Constant[value = <Tensor>]()\n",
      "  %linear_4.b_0 = Constant[value = <Tensor>]()\n",
      "  %linear_5.w_0 = Constant[value = <Tensor>]()\n",
      "  %linear_5.b_0 = Constant[value = <Tensor>]()\n",
      "  %conv2d_3.tmp_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [1, 1]](%x, %conv2d_2.w_0)\n",
      "  %Constant_0 = Constant[value = <Tensor>]()\n",
      "  %Reshape_0 = Reshape(%conv2d_2.b_0, %Constant_0)\n",
      "  %conv2d_3.tmp_1 = Add(%conv2d_3.tmp_0, %Reshape_0)\n",
      "  %pool2d_0.tmp_0 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%conv2d_3.tmp_1)\n",
      "  %Shape_0 = Shape(%pool2d_0.tmp_0)\n",
      "  %Slice_0 = Slice[axes = [0], ends = [1], starts = [0]](%Shape_0)\n",
      "  %Constant_1 = Constant[value = <Tensor>]()\n",
      "  %Concat_0 = Concat[axis = 0](%Slice_0, %Constant_1)\n",
      "  %flatten_3.tmp_0 = Reshape(%pool2d_0.tmp_0, %Concat_0)\n",
      "  %linear_6.tmp_0 = MatMul(%flatten_3.tmp_0, %linear_4.w_0)\n",
      "  %linear_6.tmp_1 = Add(%linear_6.tmp_0, %linear_4.b_0)\n",
      "  %relu_0.tmp_0 = Relu(%linear_6.tmp_1)\n",
      "  %linear_7.tmp_0 = MatMul(%relu_0.tmp_0, %linear_5.w_0)\n",
      "  %linear_7.tmp_1 = Add(%linear_7.tmp_0, %linear_5.b_0)\n",
      "  return %linear_7.tmp_1\n",
      "}\n",
      "input name  ['x']\n",
      "output name  ['linear_7.tmp_1']\n",
      "val device  cuda\n",
      "val shape  [128, 1, 28, 28]\n",
      "val data type  tensor(float)\n",
      "is_tensor  True\n",
      "array_equal  True\n",
      "providers  CUDAExecutionProvider\n",
      "sess env  ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "<class 'list'>\n",
      "[[ 0.763783   -0.16668957 -0.16518936 ...  0.07235195 -0.01643395\n",
      "   0.06049304]\n",
      " [ 1.8068395  -0.74552214  0.3836273  ...  0.75880224 -0.88902843\n",
      "   0.32921085]\n",
      " [ 0.2381373  -0.14879732 -0.21634206 ... -0.06579521 -0.461351\n",
      "   0.15305203]\n",
      " ...\n",
      " [ 0.97004616  0.07693841  0.05774391 ...  0.21991295  0.07179791\n",
      "  -0.22383693]\n",
      " [ 0.5787286  -0.34370935 -0.12914304 ... -0.03083546 -0.01817408\n",
      "  -0.5147962 ]\n",
      " [ 0.60808766 -0.12549599 -0.32095248 ... -0.32175955 -0.03176413\n",
      "  -0.06790417]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nFor example ['CUDAExecutionProvider', 'CPUExecutionProvider']\\n    means execute a node using CUDAExecutionProvider if capable, otherwise execute using CPUExecutionProvider.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_DEVICE = \"cuda\" if S_DEVICE == \"gpu\" else S_DEVICE\n",
    "model = onnx.load(S_ONNX_MODEL_PATH + \".onnx\")\n",
    "print(onnx.checker.check_model(model))  # Check that the model is well formed\n",
    "print(onnx.helper.printable_graph(model.graph))  # Print a human readable representation of the graph\n",
    "ls_input_name, ls_output_name = [input.name for input in model.graph.input], [output.name for output in model.graph.output]\n",
    "print(\"input name \", ls_input_name)\n",
    "print(\"output name \", ls_output_name)\n",
    "s_input_name = ls_input_name[0]\n",
    "\n",
    "x_input = X_train[:N_BATCH * 2, :, :, :].astype(np.float32)\n",
    "ort_val = ort.OrtValue.ortvalue_from_numpy(x_input, S_DEVICE, N_DEVICE_ID)\n",
    "print(\"val device \", ort_val.device_name())\n",
    "print(\"val shape \", ort_val.shape())\n",
    "print(\"val data type \", ort_val.data_type())\n",
    "print(\"is_tensor \", ort_val.is_tensor())\n",
    "print(\"array_equal \", np.array_equal(ort_val.numpy(), x_input))\n",
    "providers = 'CUDAExecutionProvider' if S_DEVICE == \"cuda\" else 'CPUExecutionProvider'\n",
    "print(\"providers \", providers)\n",
    "ort_session = ort.InferenceSession(S_ONNX_MODEL_PATH + \".onnx\", providers=[providers])  # gpu运行\n",
    "ort_session.set_providers([providers])\n",
    "outputs = ort_session.run(None, {s_input_name: ort_val})\n",
    "print(\"sess env \", ort_session.get_providers())\n",
    "print(type(outputs))\n",
    "print(outputs[0])\n",
    "'''\n",
    "For example ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "    means execute a node using CUDAExecutionProvider if capable, otherwise execute using CPUExecutionProvider.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcdb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24a6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5b5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914d834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
